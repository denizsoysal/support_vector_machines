% The Bayesian framework can also be used to tune
% and to analyze the LS-SVM regressor. The basic result from the Bayesian framework for the
% LS-SVM is the derivation of the probability that the data points are generated by the given
% model. This is called the posterior probability. This probability criterion is expressed as a
% number. There are 3 variants: the posterior with respect to the model parameters alpha
% and b, the posterior with respect to the regularization constant gam and the posterior with
% respect to the choice of the kernel and its parameter sig2. The cost (negative logarithm of
% the posteriors) is computed by the function call

clear,clc,clf
close all;

%dataset : noisy sinc
X = ( -3:0.01:3)';
Y = sinc (X) + 0.1.* randn ( length (X), 1);

%training and test sets :

Xtrain = X (1:2: end);
Ytrain = Y (1:2: end);
Xtest = X (2:2: end);
Ytest = Y (2:2: end);



sig2 = 0.4;
gam = 10;
crit_L1 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 1);
crit_L2 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 2);
crit_L3 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 3);

[~, alpha ,b] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 1);
[~, gam] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 2);
[~, sig2 ] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 3);

sig2e = bay_errorbar ({ Xtrain , Ytrain , 'f', gam , sig2 }, 'figure');